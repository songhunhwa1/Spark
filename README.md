## Spark 배경

- 빅데이터 시대 → 하둡의 탄생
- 유의미한 결과를 얻기 위해선 여전히 SQL은 중요한 언어
  - R, Python 등 출현 그러나 작은 규머의 데이터셋에서 작동
- 그런데 대규모 데이터셋에서는? 
- 분산컴퓨팅에 대한 고민 필요 (예. 네트워크 < 인메모리 속도가 월등히 빠름)
- 즉 고도의 별령 실행 코드를 쉽게 작성 + 분산환경에 적합한 프로그래밍 패터다임이 필요
- 하둡생태계는 클러스터 환경을 단일 컴퓨터환경처럼 다룰수 있게 추상화 제공
  - DNA 처리와 같은 경우, 저수준 분산 프레임워크 (C언어 및 분산 네트환경에 대한 이해 필요)
  - POSIX 파일의 경우 단일 데이터 스트림으로만 읽기 가능 → 병렬화 어려움
- 하둡생태계는 알아서 각 노드에 저장소에 분산, 일을 쪼개고, 오류를 자동으로 복구함

## 데이터 과학
- 데이터과학 → 분석/알고리즘 고려 필요
- 대용량 데이터 전처리 (필터링, 추출, 조인 등)
- 반복 작업 (SGD 최적화, 파라메터 튜닝 등)
- 다양한 EDA 및 운영을 위한 분석을 통한 고도화

## 아파치 스파크
- 맵리듀스 기반(병렬처리 모델) 장점:
  - 선형 확장성
  - 일을 작은 단위 작업으로 쪼개서 부분이 전체에 영향X
- 스파크
  - 위 장점을 포함하여 DAG 형태 비순환형태로 연산
  - 간소화된 데이터파이프라인 API 제공
  - 인메모리 처리
  - 분석가 입장에서 업무 효율을 매우 높여줌 (하나의 프레임워크에서 모든 프로세스 처리 가능)
  - 하둡 생태계와 연동 (Parquet, CSV, NoSQL 등)

## 데이터셋 특성
- RDD는 1.X 버전 (메모리 비효율적 사용, 대시기간 길고, 코드 복잡성 높음, 범용성 낮음)
- Dataset, DataFrame - 2.x 버전이상에서 이용
- SparkSQL과 상호운용해 컬럼 기반의 연산 수월 (분석가에게 친숙)

## Spark 주요 내용

